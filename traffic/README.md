When I experimented with this project, I changed one variable at a time, made observations, and tried to create the best combination. An important thing to keep in mind was my goal. I wanted to not only maximize the final accuracy but also minimize time. One convolutional and pooling layer was fine for this project, as the images had already been scaled so small. I found that the filter and pool sizes affected the runtime a lot, the ones I have selected were much better than others. Multiple large hidden layers were necessary because the project was so complex. A lot of filters also helped the network understand the problem much better. But the network was okay without too much dropout because most of the time, there were so many nodes, so no single one controlled too much, and it worked well with the testing. A lot of the time, I noticed factors improving learning time, but not so much the accuracy as the accuracy converged. Because of this, I usually made decisions based on time. But altogether, it's all about the tradeoff, and how much time one is willing to spend affects how accurate the build will be. In this case, I tried to make the best netwrok that could run in under 5 minutes (the maximum length of the screencast).